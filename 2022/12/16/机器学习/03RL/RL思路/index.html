<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="google-site-verification" content="" />
  <meta name="referrer" content="unsafe-url">
  
  <title>RL思路</title>
  <meta name="author" content="Peirsist">
  <meta name="description" content="强化学习（三）--Reinforce算法_BUAA小乔的博客-CSDN博客_reinforce算法

科老师的课程

GitHub - PaddlePaddle/PARL: A high-performance distributed training framework for Reinf">
  
  
  <meta property="og:title" content="RL思路"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:site_name" content="EEWIKI"/>
  <link href="/apple-touch-icon-precomposed.png" sizes="180x180" rel="apple-touch-icon-precomposed">
  <link rel="alternate" href="/atom.xml" title="EEWIKI" type="application/atom+xml">
  <link rel="stylesheet" href="/css/m.min.css">
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <a id="top"></a>
  <div id="main">
    <div class="main-ctnr">
      <div class="behind">
  <a href="/" class="back black-color">
    <svg class="i-close" viewBox="0 0 32 32" width="22" height="22" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3">
        <path d="M2 30 L30 2 M30 30 L2 2"></path>
    </svg>
  </a>
  
</div>


  <article class="standard post">
    <div class="title">
      
  
    <h1 class="page-title center">
        RL思路
    </h1>
  


    </div>
    <div class="meta center">
      <time datetime="2022-12-16T02:54:41.000Z" itemprop="datePublished">
  <svg class="i-calendar" viewBox="0 0 32 32" width="16" height="16" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
    <path d="M2 6 L2 30 30 30 30 6 Z M2 15 L30 15 M7 3 L7 9 M13 3 L13 9 M19 3 L19 9 M25 3 L25 9"></path>
  </svg>
  &nbsp;
  2022-12-16
</time>


    
    &nbsp;
    <svg class="i-tag" viewBox="0 0 32 32" width="16" height="16" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
      <circle cx="24" cy="8" r="2"></circle>
      <path d="M2 18 L18 2 30 2 30 14 14 30 Z"></path>
    </svg>
    &nbsp;
    <a href="/categories/强化学习/">强化学习</a>





    </div>
    <hr>
    
    <div class="picture-container">
      
    </div>
    <p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37333048/article/details/115323980">强化学习（三）--Reinforce算法_BUAA小乔的博客-CSDN博客_reinforce算法</a></p>
<ol type="1">
<li><p>科老师的课程</p>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PARL">GitHub - PaddlePaddle/PARL: A high-performance distributed training framework for Reinforcement Learning</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1yv411i7xd?p=20&amp;vd_source=83831fc0970a6c8704479f7cfc679937">Lesson5-3-四轴飞行器与创意赛_哔哩哔哩_bilibili</a></li>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/education/group/info/1335">飞桨AI Studio - 人工智能学习实训社区 (baidu.com)</a></li>
</ol></li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/477982098">强化学习入门：环境（含机器人）和代码库介绍 - 知乎 (zhihu.com)</a></p>
<p>一本好的强化学习教材，需要满足以下 3 点：</p>
<ol type="1">
<li>讲好基础，包括 MDP、Q-Learning 等。这个大部分教材都能做到。</li>
<li>跟踪最近的算法，比如 DDPG、PPO、SAC 等。这个也有不少教材能满足。</li>
<li>提供与内容匹配的良好代码，用 PyTorch 或 Tensorflow。这个对初学者最为重要，只有少部分教材可以。</li>
</ol></li>
</ol>
<p>对于入门教程，在精不在多。除了 Sutton 的开山之作，在 2022 年的今天，推荐 2 本教材：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://hrl.boyuai.com/">《动手学强化学习》</a> ：上海交通大学张伟楠、俞勇团队出品，内容从基础到前沿都有覆盖，还提供了免费视频课程和代码（PyTorch）。</li>
<li><a target="_blank" rel="noopener" href="https://deepreinforcementlearningbook.org/">《深度强化学习：基础、研究与应用》Deep Reinforcement Learning Book</a> ：北京大学董豪老师联合普林斯顿、UCB 等大学出品，中文/英文电子版都可免费下载，代码（Tensorflow）齐全。</li>
</ul>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/344196096">强化学习路线推荐及资料整理 - 知乎 (zhihu.com)</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/461334575">深度强化学习入门资料推荐 - 知乎 (zhihu.com)</a></li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1BE411W7TA?p=2&amp;vd_source=83831fc0970a6c8704479f7cfc679937">深度强化学习(2/5)：价值学习 Value-Based Reinforcement Learning_哔哩哔哩_bilibili</a></li>
<li></li>
</ol>
<p>贝尔曼方程是用来求解 state value 的，而 state value 的大小可以表明一个 policy 的好坏，也就是说计算 state value 可以用来 policy evaluation。state value 越大，policy 越好。</p>
<p>事实上 action value 才是用来评判一个 policy 好坏的。action values can be used to evaluate actions.</p>
<p>贝尔曼最优方程用来求解最优 policy 和最优 state value，一个方程中有 policy 和 state value 两个未知量</p>
<p>凡是需要大量的采样，然后实验，最后用实验结果来近似的一种方法都可以成为蒙特卡洛估计的方法。</p>
<p>TD 算法依赖数据，不依赖模型来实现强化学习</p>
<p>因为一个 agent 在环境当中它一个时刻只能访问一个状态</p>
<hr>
<p>通过在环境中进行演算（Roll-out）收集多轮交互信息，即在环境中根据当前的状态和决策策略形成一条具体的包含一系列状态、动作和奖励信息的探索轨迹。在一般的无模型学习中，智能体将在真实的环境中在线演算，并将获得的多轮交互信息用于策略学习。</p>
<p><strong>轨迹（Trajectories）</strong> 常常也被称作 <strong>回合 (episodes)</strong> 或者 <strong>rollouts</strong>。</p>
<ol type="1">
<li><a target="_blank" rel="noopener" href="http://www.deeprlhub.com/d/143-2-rollout-episode-epoch-step-trajectory">强化学习中的奇怪概念2-rollout-episode-epoch-step-trajectory - 深度强化学习实验室 (deeprlhub.com)</a></li>
<li><a target="_blank" rel="noopener" href="https://spinningup.qiwihui.com/zh_CN/latest/spinningup/rl_intro.html">第一部分：强化学习中的核心概念 — Spinning Up 文档 (qiwihui.com)</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/steven-yang/p/6481772.html">强化学习读书笔记 - 00 - 术语和数学符号 - SNYang - 博客园 (cnblogs.com)</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40206371/article/details/122065998">python 笔记 ：Gym库 （官方文档笔记）_UQI-LIUWJ的博客-CSDN博客_gym库</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/482821112">Gym库中关于Spaces库的使用方法 - 知乎 (zhihu.com)</a></li>
<li><strong><a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_39620217/article/details/117081680">【编写环境一】遇到常见python函数处理方式_汀、的博客-CSDN博客_spaces.multidiscrete</a></strong></li>
</ol>
<p>（转载）</p>
<p>对这几个概念，我一直理解不能。<br>
先抛个砖，希望有更确切的中文定义~</p>
<ol type="1">
<li>rollout：在 CS 相关论文中，一般 rollout 表示一次试验，一条轨迹。就比如我们我们用 MC 仿真出了一个 episode，这个 episode 就是一个 rollout。<br>
</li>
<li>episode：一条轨迹<br>
</li>
<li>epoch：可能有多个轨迹？因为强化里面的 epoch 和深度学习的不一样，我在 HER 相关的论文里看到的 epoch，是有 50 个 episode 组成的。<br>
</li>
<li>trajectory：一条轨迹<br>
</li>
<li>cycle:<br>
</li>
<li>simulation step：智能体和环境的一次交互<br>
</li>
<li>update step：网络更新一次</li>
</ol>
<p>有的甚至在不同的论文和代码里，代表的含义都不一样。</p>
<hr>
<h1 id="gym-库">Gym 库</h1>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://gymnasium.farama.org/api/spaces/fundamental/">官方文档Fundamental Spaces - Gymnasium Documentation (farama.org)</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/370608508">强化学习gym官方文档翻译 - 知乎 (zhihu.com)</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40206371/article/details/122065998">python 笔记 ：Gym库 （官方文档笔记）_UQI-LIUWJ的博客-CSDN博客_gym库</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/482821112">Gym库中关于Spaces库的使用方法 - 知乎 (zhihu.com)</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/hl1hl/article/details/89229408">gym.spaces.Discrete()_双木青橙的博客-CSDN博客_spaces.discrete</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_39620217/article/details/114533928">【一】MADDPG-单智能体|多智能体总结（理论、算法）_汀、的博客-CSDN博客_多智能体理论</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_39620217/article/details/117081680">【编写环境一】遇到常见python函数处理方式_汀、的博客-CSDN博客_spaces.multidiscrete</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43255962/article/details/91628492">RLlib Environments_快乐地笑的博客-CSDN博客</a></li>
<li></li>
</ol>


  </article>
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <div class="busuanzi center">
    page PV:&nbsp;<span id="busuanzi_value_page_pv"></span>&nbsp;・&nbsp;
    site PV:&nbsp;<span id="busuanzi_value_site_pv"></span>&nbsp;・&nbsp;
    site UV:&nbsp;<span id="busuanzi_value_site_uv"></span>
  </div>


    





    </div>
  </div>
  <footer class="page-footer"><div class="clearfix">
</div>
<div class="right-foot">
    <div class="firstrow">
        <a href="#top" target="_self">
        <svg class="i-caret-right" viewBox="0 0 32 32" width="24" height="24" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3">
            <path d="M10 30 L26 16 10 2 Z"></path>
        </svg>
        </a>
        © peirsist 2021
    </div>
    <div class="secondrow">
        <a target="_blank" rel="noopener" href="https://github.com/gaoryrt/hexo-theme-pln">
        Theme Pln
        </a>
    </div>
</div>
<div class="clearfix">
</div>
</footer>
  <script src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script>
<script src="/js/search.min.js"></script>
<script type="text/javascript">

// disqus scripts


// dropdown scripts
$(".dropdown").click(function(event) {
  var current = $(this);
  event.stopPropagation();
  $(current).children(".dropdown-content")[($(current).children(".dropdown-content").hasClass("open"))?'removeClass':'addClass']("open")
});
$(document).click(function(){
    $(".dropdown-content").removeClass("open");
})

var path = "/search.xml";
searchFunc(path, 'local-search-input', 'local-search-result');

</script>

</body>
</html>
